<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PINN - Physics-Informed Neural Network</title>
  <link rel="stylesheet" href="../../styles.css" />
  <link rel="stylesheet" href="styles.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>
  <div class="project-container">
    <header class="project-header">
      <a href="../../index.html" class="back-link">
        <i class="fas fa-arrow-left"></i> Back to Main
      </a>
      <h1>PINN</h1>
      <h2>Physics-Informed Neural Network</h2>
    </header>

    <main class="project-content">
      <section class="content-block">
        <div class="text-content">
          <h3>Inverse Modeling Neural Network with Physics-Informed Loss</h3>
          <p>
            This approach combines data-driven learning with physics-based
            modeling to infer key physical parameters from observed data. The
            goal is to develop a neural network–physics hybrid model that
            enables inverse modeling of dynamic systems, using simulation
            constraints to ensure physically meaningful predictions. This
            framework is especially relevant for applications such as
            reduced-order modeling (ROM) in biomedical systems, e.g.,
            predicting the progression of arterial occlusion from noninvasive
            measurements like tissue oxygenation.
          </p>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Purpose</h3>
          <p>
            The primary objective is to infer hidden physical parameters—such
            as diffusivity and source strength in a heat conduction model—by
            comparing simulated outputs driven by learned parameters to noisy
            observed data. Unlike traditional forward models, which predict
            system behavior from known parameters, inverse modeling solves the
            harder problem of recovering the parameters themselves.
          </p>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Advantages</h3>
          <ul class="feature-list">
            <li><strong>End-to-End Differentiability:</strong> The entire model,
              including the physics solver, is differentiable, enabling
              gradient-based training.</li>
            <li><strong>Physical Interpretability:</strong> The learned
              features correspond to meaningful physical quantities.</li>
            <li><strong>Simulation-Consistent Learning:</strong> The model
              respects the underlying physics throughout the learning
              process.</li>
            <li><strong>Efficiency:</strong> The model learns a reduced
              representation of a full simulation, offering potential speed-ups
              during deployment.</li>
          </ul>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Feasibility and Precedents</h3>
          <p>
            This methodology is well-supported by existing literature in
            scientific machine learning. Similar hybrid and physics-informed
            frameworks have been applied successfully in fields like
            aerospace, fluid mechanics, and structural dynamics (e.g., Journal
            of Fluids and Structures, 2017; ERCOFTAC workshops, 2025). These
            precedents validate both the theoretical soundness and practical
            relevance of embedding physical constraints into learning
            pipelines, especially when data are limited and interpretability is
            critical.
          </p>
        </div>
      </section>

      <!-- Case 1 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 1 — Inverse modeling a 1D heat conduction system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_Dif.py">Code implementation 1</a></p>
          <ul>
            <li><strong>Heat Equation:</strong> \( \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2} + \beta \sin(\pi x) \)</li>
            <li><strong>Analytical Solution:</strong>
              \[
              u(x, t) = \sin(\pi x) \left[ e^{-\pi^2 \alpha t} + \frac{\beta}{\pi^2 \alpha}(1 - e^{-\pi^2 \alpha t}) \right]
              \]
            </li>
            <li><strong>Numerical Solver:</strong> Crank–Nicolson scheme is
              used for time-stepping the PDE numerically in a differentiable
              manner.</li>
            <li><strong>Neural Network:</strong> Maps noisy field
              \(u(x, t)\) to \((\alpha, \beta) \in (0, 1)^2\) using a
              two-layer MLP.</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), ensuring that learned parameters replicate the observed dynamics.</li>
          </ul>
          <img src="PINN_Training_Convergence.png" alt="Training convergence plot" class="visual-content" />
        </div>
      </section>

      <!-- Case 2 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 2 — Inverse modeling a 1D advection–diffusion system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_AdvDif.py">Code implementation 2</a></p>
          <ul>
            <li><strong>Advection–Diffusion Equation:</strong> \( \frac{\partial u}{\partial t} + v \frac{\partial u}{\partial x} = \alpha \frac{\partial^2 u}{\partial x^2} \)</li>
            <li><strong>Analytical Solution:</strong>
              \[
              u(x,t) = \frac{1}{\sqrt{4\pi \alpha t}} \exp\left(-\frac{(x - vt - 0.5)^2}{4\alpha t}\right)
              \]
            </li>
            <li><strong>Numerical Solver:</strong> Implicit finite difference
              scheme handling both advection and diffusion; inlet conditions
              are defined by the analytical solution.</li>
            <li><strong>Neural Network:</strong> Learns to predict
              \((\alpha, v) \in (0,1)^2\) from noisy snapshots of \(u(x,t)\).</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), ensuring physics-consistent parameter recovery.</li>
          </ul>
          <img src="PNN_AdvDif.png" alt="Advection-Diffusion training convergence plot" class="visual-content" />
        </div>
      </section>

      <!-- Case 3 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 3 — Inverse modeling a 1D advection–diffusion–reaction system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_AdvDifRea.py">Code implementation 3</a></p>
          <ul>
            <li><strong>Advection–Diffusion–Reaction Equation:</strong> \( \frac{\partial u}{\partial t} + v \frac{\partial u}{\partial x} = \alpha \frac{\partial^2 u}{\partial x^2} + R(u) \), where \( R(u) \) models spatially heterogeneous reaction terms.</li>
            <li><strong>Synthesized Data Samples:</strong> Noisy measurements of \( u(x,t) \) are generated by simulating the forward PDE solver with known parameters \((\alpha, v, r_0, r_1)\) at random time points. Gaussian noise is added to simulate observation uncertainty.</li>
            <li><strong>Numerical Solver:</strong> Implicit finite difference scheme that handles all three processes—advection, diffusion, and spatially varying reactions—implemented as a differentiable module for backpropagation.</li>
            <li><strong>Neural Network:</strong> Maps input pairs of noisy solution fields and time into predicted parameters \((\alpha, v, r_0, r_1)\), using a two-layer MLP with bounded sigmoid output scaled to physical ranges.</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), comparing simulated outputs under predicted parameters to noisy observations, enabling inverse inference.</li>
          </ul>
          <img src="PNN_AdvDifRea.png" alt="Advection-Diffusion-Reaction training convergence plot" class="visual-content" />
        </div>
      </section>
  <section>
    <h2>Case 4 — Inverse modeling a 1D hemodynamic system</h2>
    <p>The governing equations are based on conservation of mass and momentum, expressed in terms of flow rate <var>Q(x,t)</var> and cross‑sectional area <var>A(x,t)</var>:</p>
    <li><strong>Conservation of Mass:</strong></li>
    <p>$$\frac{\partial A}{\partial t} + \frac{\partial Q}{\partial x} = 0$$</p>
    <li><strong>Conservation of Momentum:</strong></li>
<p>
$$
\frac{\partial Q}{\partial t}
+ \frac{\partial}{\partial x}\left(\alpha \frac{Q^2}{A}\right)
+ \frac{A}{\rho}\,\frac{\partial P}{\partial x}
=
-\,K_R \frac{Q}{A}
+ \nu\,\frac{\partial^2 Q}{\partial x^2}
$$
</p>
<p>
The pressure \(P\) is still given by:
</p>
<p>
$$
P = P_0 + \beta\left(\sqrt{A} - \sqrt{A_0}\right)
$$
</p>
    <p>To numerically solve these PDEs, boundary conditions are required:</p>
    <li><strong>Inlet Boundary Conditions</strong></li>
    <ul>
      <li>Prescribe both <var>Q(t)</var> and <var>P(t)</var> (or equivalently <var>A(t)</var>) at the inlet to uniquely define inflow and pressure dynamics.</li>
    </ul>
    <li><strong>Outlet Boundary Conditions</strong></li>
    <p>Only <var>P(t)</var> is prescribed; <var>Q(t)</var> is inferred using one of four common models:</p>
    <ol>
      <li><strong>Dirichlet (Prescribed Pressure)</strong>: directly specify <var>P(t)</var>.</li>
      <li><strong>Resistance</strong>: <var>P(t) = R Q(t)</var>.</li>
      <li><strong>RCR (Windkessel)</strong>: three-element model relating <var>P</var> and <var>Q</var> via resistance and compliance.</li>
      <li><strong>Impedance/Structured Tree</strong>: uses impedance or structured tree model—<var>Q(t)</var> is computed via convolution with the inverse FT of admittance.</li>
    </ol>
    <p>In all cases, the user prescribes <var>P(t)</var> (or its defining parameters), and the solver infers <var>Q(t)</var> based on the chosen outlet model.</p>
    <h4>Numerical Algorithm</h4>
    <p><strong>Unknown fields:</strong> \(P_{i,j}, Q_{i,j}, A_{i,j}\) over \(i=0,\dots,N_x-1\); \(j=0,\dots,N_t-1\). Total unknowns: <em>3·N<sub>x</sub>·N<sub>t</sub></em>.</p>

    <p><strong>Constraints:</strong></p>
    <ul>
      <li><strong>Initialization</strong> (\(j=0\)): \(P_{i,0}, Q_{i,0}, A_{i,0}\) are prescribed.</li>
      <li><strong>Periodicity</strong> (\(j=N_t-1\)): \(P_{i,N_t-1}=P_{i,0}\), \(Q_{i,N_t-1}=Q_{i,0}\), \(A_{i,N_t-1}=A_{i,0}\).</li>
      <li><strong>Boundary Conditions</strong>:
        <ul>
          <li>Inlet (\(i=0\)): both \(Q_{0,j}\) and \(P_{0,j}\) provided.</li>
          <li>Outlet (\(i=N_x-1\)): \(P_{N_x-1,j}\) prescribed; \(Q_{N_x-1,j}\) inferred using SimVascular models (Resistance, RCR/Windkessel, Impedance/Structured-tree).</li>
        </ul>
      </li>
      <li><strong>PDE equations</strong> (interior nodes \(0<i<N_x-1\), \(0<j<N_t-1\)) using central finite differences:
        <p>Mass: \(\frac{A_{j+1,i}-A_{j,i}}{\Delta t} + \frac{Q_{j,i+1}-Q_{j,i-1}}{2\Delta x} = 0\)</p>
        <p>Momentum: \(\frac{Q_{j+1,i}-Q_{j,i}}{\Delta t} + \frac{\partial}{\partial x}(\alpha \frac{Q^2}{A}) + \frac{A}{\rho}\frac{\partial P}{\partial x} + K_R \frac{Q}{A} = 0\)</p>
        <p>Constitutive: \(P_{j,i} - [P_0 + \beta (\sqrt{A_{j,i}} - \sqrt{A_0})] = 0\)</p>
      </li>
    </ul>

    <p>Altogether, these give \(3(N_t-2)(N_x-2)\) equations matching the interior unknowns.</p>

    <h4>Solver outline:</h4>
    <ol>
      <li>Assemble residual vector \(\mathbf{R}(U)\) across all unknowns \(U = \mathrm{vec}(P,Q,A)\).</li>
      <li>Solve nonlinear system \(\mathbf{R}(U)=0\) using Newton–Krylov:
        <ul>
          <li>Approximate Jacobian–vector product via finite differences.</li>
          <li>Solve correction \(\Delta U\) using GMRES + ILU preconditioner (avoiding direct factorization errors).</li>
        </ul>
      </li>
      <li>Iterate until convergence \(\|\mathbf{R}\| < tol\).</li>
    </ol>

    <p>This fully couples the 1D system in space and time, enforcing periodic behavior and solving for the complete space-time field in a single unified step.</p>
      <section class="content-block">
        <div class="text-content">

          <h3>Case 5 — Dual Pipeline Framework for Wearable Physiological Modeling</h3>

          <h4>Executive Summary</h4>
          <p>
            I propose a bi-directional modeling architecture that combines 
            (1) a forward, physiology-constrained generative pipeline (Pipeline A), and 
            (2) a reverse measurement-to-event inference pipeline (Pipeline B). 
            Pipeline A provides physiologically structured signal representations, 
            while Pipeline B performs event detection using those structured outputs 
            as engineered features.
          </p>

          <!-- ========================= -->
          <!-- Pipeline A unchanged     -->
          <!-- ========================= -->

          <h4>Pipeline A – Forward (Mechanistic Generative Model)</h4>
          <p>
            <strong>Purpose:</strong> Generate realistic wearable biosignals (e.g., heart rate, HRV,
            accelerometry) from latent physiological and contextual states.
          </p>

          <h5>Structure</h5>
          <ul>
            <li><strong>Input Layer – Exogenous Drivers</strong><br>
              Sleep/wake timing, activity context, stressor indicators, circadian phase.
            </li>
            <li><strong>Hidden Layer – Latent Physiological Dynamics</strong><br>
              Autonomic balance, fatigue/recovery state, respiratory modulation.
            </li>
            <li><strong>Interpretable Output Parameters</strong><br>
              Heart rate set-points, responsiveness gains, baroreflex sensitivity proxies.
            </li>
            <li><strong>Physics Measurement Layer</strong><br>
              Differentiable physiological signal model translating latent state to HR/HRV and accelerometry streams under realistic noise and artifact models.
            </li>
          </ul>

          <h5>Deliverables</h5>
          <ul>
            <li>A differentiable generative simulator capable of producing wearable biosignals consistent with underlying states, used for:</li>
            <ul>
              <li>Synthetic data generation</li>
              <li>Personalized calibration</li>
              <li>Counterfactual exploration (what-if stress/cognitive load scenarios)</li>
            </ul>
          </ul>

          <p>
            This pipeline leverages mechanistic models and neural ODE–style physics layers (PINNs)
            to build physiologically grounded generative modules.
          </p>

          <!-- ================================================= -->
          <!-- ============ MODIFIED PIPELINE B ================= -->
          <!-- ================================================= -->

          <h4>Pipeline B – Inference (Measurement-to-Event, Reverse Information Flow)</h4>

          <p>
            <strong>Purpose:</strong> Infer user states (stress, cognitive load, sleep disruption) 
            directly from wearable measurements by reversing the information flow of Pipeline A.
          </p>

          <p>
            Pipeline B does <strong>not</strong> reconstruct full physiological mechanisms. 
            Instead, it operates in measurement space. It treats the outputs of 
            Pipeline A’s Physics Measurement Layer as structured inputs and maps them 
            directly to event probabilities.
          </p>

          <p>
            In this architecture, <strong>Pipeline A functions as advanced feature engineering</strong>. 
            It transforms raw wearable signals into physiologically meaningful representations, 
            reducing noise sensitivity and improving interpretability. 
            Pipeline B then performs robust event inference using these structured features.
          </p>

          <h4>Core Components</h4>

          <ul>
            <li>
              <strong>1. Structured Feature Extraction (from Pipeline A)</strong><br>
              Rather than relying solely on raw HR or accelerometry, Pipeline B consumes:
              <ul>
                <li>Derived HRV indices (time-domain and frequency-domain)</li>
                <li>Autonomic balance indicators inferred by Pipeline A</li>
                <li>Regime classification (rest vs. movement)</li>
                <li>Signal quality scores</li>
                <li>Temporal stability metrics</li>
              </ul>
              These features are physiologically grounded outputs generated by Pipeline A.
            </li>

            <li>
              <strong>2. Multi-Scale Temporal Aggregation</strong><br>
              Features are computed across multiple time windows (e.g., 30s, 5min, 60min) 
              to capture both transient responses and sustained deviations.
            </li>

            <li>
              <strong>3. Event Inference Model</strong><br>
              A supervised or semi-supervised model maps structured features to event probabilities:
              <ul>
                <li>Logistic regression or gradient boosting for interpretable baselines</li>
                <li>Lightweight neural network for nonlinear interactions</li>
                <li>Optional anomaly detection for emerging events</li>
              </ul>
              The model outputs calibrated probabilities and confidence scores.
            </li>

            <li>
              <strong>4. Uncertainty & Robustness Handling</strong><br>
              Pipeline B explicitly accounts for:
              <ul>
                <li>Motion-induced artifacts</li>
                <li>Circadian baseline shifts</li>
                <li>Device-specific noise patterns</li>
              </ul>
              This improves generalization in uncontrolled real-world environments.
            </li>
          </ul>

          <h4>Relationship Between Pipeline A and Pipeline B</h4>

          <p>
            Pipeline B can operate independently using raw features. However, 
            without Pipeline A, inference relies purely on statistical correlations 
            and may be vulnerable to confounding and overfitting.
          </p>

          <p>
            By introducing Pipeline A:
          </p>

          <ul>
            <li>Signal representations become physiologically interpretable.</li>
            <li>Feature space becomes structured and lower-noise.</li>
            <li>Generalization improves across subjects and devices.</li>
            <li>Event inference becomes explainable rather than purely correlational.</li>
          </ul>

          <p>
            Therefore, Pipeline A provides structured physiological feature engineering, 
            while Pipeline B provides operational event detection. 
            Together they form a coherent forward–reverse modeling system.
          </p>

        </div>
      </section>
</main>

    <footer class="project-footer">
      <p>&copy; 2025 Zhenwen Wan. All rights reserved.</p>
    </footer>
  </div>
</body>

</html>

