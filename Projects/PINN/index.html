<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PINN - Physics-Informed Neural Network</title>
    <link rel="stylesheet" href="../../styles.css">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>

<body>
    <div class="project-container">
        <header class="project-header">
            <a href="../../index.html" class="back-link">
                <i class="fas fa-arrow-left"></i> Back to Main
            </a>
            <h1>PINN</h1>
            <h2>Physics-Informed Neural Network</h2>
        </header>

        <main class="project-content">
            <section class="content-block">
                <div class="text-content">
                    <h3>Inverse Modeling Neural Network with Physics-Informed Loss</h3>
                    <p>This approach combines data-driven learning with physics-based modeling to infer key physical parameters from observed data. The goal is to develop a neural network–physics hybrid model that enables inverse modeling of dynamic systems, using simulation constraints to ensure physically meaningful predictions. This framework is especially relevant for applications such as reduced-order modeling (ROM) in biomedical systems, e.g., predicting the progression of arterial occlusion from noninvasive measurements like tissue oxygenation.</p>
                </div>
            </section>

            <section class="content-block">
                <div class="text-content">
                    <h3>Purpose</h3>
                    <p>The primary objective is to infer hidden physical parameters—such as diffusivity and source strength in a heat conduction model—by comparing simulated outputs driven by learned parameters to noisy observed data. Unlike traditional forward models, which predict system behavior from known parameters, inverse modeling solves the harder problem of recovering the parameters themselves.</p>
                </div>
            </section>

            <section class="content-block">
                <div class="text-content">
                    <h3>Advantages</h3>
                    <ul class="feature-list">
                        <li><strong>End-to-End Differentiability:</strong> The entire model, including the physics solver, is differentiable, enabling gradient-based training.</li>
                        <li><strong>Physical Interpretability:</strong> The learned features correspond to meaningful physical quantities.</li>
                        <li><strong>Simulation-Consistent Learning:</strong> The model respects the underlying physics throughout the learning process.</li>
                        <li><strong>Efficiency:</strong> The model learns a reduced representation of a full simulation, offering potential speed-ups during deployment.</li>
                    </ul>
                </div>
            </section>

            <section class="content-block">
                <div class="text-content">
                    <h3>Feasibility and Precedents</h3>
                    <p>This methodology is well-supported by existing literature in scientific machine learning. Similar hybrid and physics-informed frameworks have been applied successfully in fields like aerospace, fluid mechanics, and structural dynamics (e.g., <em>Journal of Fluids and Structures</em>, 2017; ERCOFTAC workshops, 2025). These precedents validate both the theoretical soundness and practical relevance of embedding physical constraints into learning pipelines, especially when data are limited and interpretability is critical.</p>
                </div>
            </section>

            <section class="content-block">
                <div class="text-content">
                    <h3>Implementation Strategy</h3>
                    <ul class="feature-list">
                        <li><strong>Feature Extraction Layer (Neural Network):</strong> A feedforward neural network takes raw observational inputs (e.g., spatial or temporal fields generated analytically with known parameters and corrupted by noise) and learns to extract key physical parameters (e.g., α and β). These are treated as latent features that the network attempts to infer from the data.</li>

                        <li><strong>Physics Layer (Differentiable Numerical Solver):</strong> The extracted parameters are passed to a physics-based solver that numerically simulates the system using a differentiable formulation (rewritten entirely in PyTorch). This solver serves as a physics constraint layer that translates parameters into predicted system behavior, ensuring that the network's outputs conform to the known physical laws.</li>

                        <li><strong>Loss Function (Physics-Informed Supervision):</strong> The training loss is computed by comparing the numerical solution driven by predicted parameters to the original noisy observational input. This enforces that the predicted parameters, when used in simulation, reproduce the input data. All inputs are generated using fixed ground-truth parameters, and the network is trained to recover these parameters by minimizing this discrepancy.</li>
                    </ul>
                </div>
            </section>

            <section class="content-block">
                <div class="text-content">
                    <h3>Application Scenarios</h3>
		            <p>Case 1 <a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NN_Physics_Hybrid_Training.py">Code</a></p>
		            <p><strong>Mathematical Description:</strong> This case implements a physics-informed neural network to solve the inverse problem in a 1D heat conduction system. The goal is to learn physical parameters \( \alpha \) and \( \beta \) from noisy solution data \( u(x, t) \).</p>
                    <ul>
                        <li><strong>Heat Equation:</strong> \( \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2} + \beta \sin(\pi x) \)</li>
                        <li><strong>Analytical Solution:</strong> \( u(x, t) = \sin(\pi x) \left[ e^{-\pi^2 \alpha t} + \frac{\beta}{\pi^2 \alpha}(1 - e^{-\pi^2 \alpha t}) \right] \)</li>
                        <li><strong>Numerical Solver:</strong> Crank–Nicolson scheme is used for time-stepping the PDE numerically in a differentiable manner.</li>
                        <li><strong>Neural Network:</strong> Maps noisy field \( u(x, t) \) to \( (\alpha, \beta) \in (0, 1)^2 \) using a two-layer MLP.</li>
                        <li><strong>Loss:</strong> \( \mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2 \), ensuring that learned parameters replicate the observed dynamics.</li>
                    </ul>
                    <p>The following figure shows convergence of predicted parameters to the values preset for the analytical solution:</p>
                </div>
                <img src="PINN_Training_Convergence.png" alt="Training convergence plot" class="visual-content">
            </section>

        </main>

        <footer class="project-footer">
            <p>&copy; 2025 Zhenwen Wan. All rights reserved.</p>
        </footer>
    </div>
</body>

</html>

