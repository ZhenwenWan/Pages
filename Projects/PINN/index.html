<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PINN - Physics-Informed Neural Network</title>
  <link rel="stylesheet" href="../../styles.css" />
  <link rel="stylesheet" href="styles.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>
  <div class="project-container">
    <header class="project-header">
      <a href="../../index.html" class="back-link">
        <i class="fas fa-arrow-left"></i> Back to Main
      </a>
      <h1>PINN</h1>
      <h2>Physics-Informed Neural Network</h2>
    </header>

    <main class="project-content">
      <section class="content-block">
        <div class="text-content">
          <h3>Inverse Modeling Neural Network with Physics-Informed Loss</h3>
          <p>
            This approach combines data-driven learning with physics-based
            modeling to infer key physical parameters from observed data. The
            goal is to develop a neural network–physics hybrid model that
            enables inverse modeling of dynamic systems, using simulation
            constraints to ensure physically meaningful predictions. This
            framework is especially relevant for applications such as
            reduced-order modeling (ROM) in biomedical systems, e.g.,
            predicting the progression of arterial occlusion from noninvasive
            measurements like tissue oxygenation.
          </p>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Purpose</h3>
          <p>
            The primary objective is to infer hidden physical parameters—such
            as diffusivity and source strength in a heat conduction model—by
            comparing simulated outputs driven by learned parameters to noisy
            observed data. Unlike traditional forward models, which predict
            system behavior from known parameters, inverse modeling solves the
            harder problem of recovering the parameters themselves.
          </p>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Advantages</h3>
          <ul class="feature-list">
            <li><strong>End-to-End Differentiability:</strong> The entire model,
              including the physics solver, is differentiable, enabling
              gradient-based training.</li>
            <li><strong>Physical Interpretability:</strong> The learned
              features correspond to meaningful physical quantities.</li>
            <li><strong>Simulation-Consistent Learning:</strong> The model
              respects the underlying physics throughout the learning
              process.</li>
            <li><strong>Efficiency:</strong> The model learns a reduced
              representation of a full simulation, offering potential speed-ups
              during deployment.</li>
          </ul>
        </div>
      </section>

      <section class="content-block">
        <div class="text-content">
          <h3>Feasibility and Precedents</h3>
          <p>
            This methodology is well-supported by existing literature in
            scientific machine learning. Similar hybrid and physics-informed
            frameworks have been applied successfully in fields like
            aerospace, fluid mechanics, and structural dynamics (e.g., Journal
            of Fluids and Structures, 2017; ERCOFTAC workshops, 2025). These
            precedents validate both the theoretical soundness and practical
            relevance of embedding physical constraints into learning
            pipelines, especially when data are limited and interpretability is
            critical.
          </p>
        </div>
      </section>

      <!-- Case 1 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 1 — Inverse modeling a 1D heat conduction system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_Dif.py">Code implementation 1</a></p>
          <ul>
            <li><strong>Heat Equation:</strong> \( \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2} + \beta \sin(\pi x) \)</li>
            <li><strong>Analytical Solution:</strong>
              \[
              u(x, t) = \sin(\pi x) \left[ e^{-\pi^2 \alpha t} + \frac{\beta}{\pi^2 \alpha}(1 - e^{-\pi^2 \alpha t}) \right]
              \]
            </li>
            <li><strong>Numerical Solver:</strong> Crank–Nicolson scheme is
              used for time-stepping the PDE numerically in a differentiable
              manner.</li>
            <li><strong>Neural Network:</strong> Maps noisy field
              \(u(x, t)\) to \((\alpha, \beta) \in (0, 1)^2\) using a
              two-layer MLP.</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), ensuring that learned parameters replicate the observed dynamics.</li>
          </ul>
          <img src="PINN_Training_Convergence.png" alt="Training convergence plot" class="visual-content" />
        </div>
      </section>

      <!-- Case 2 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 2 — Inverse modeling a 1D advection–diffusion system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_AdvDif.py">Code implementation 2</a></p>
          <ul>
            <li><strong>Advection–Diffusion Equation:</strong> \( \frac{\partial u}{\partial t} + v \frac{\partial u}{\partial x} = \alpha \frac{\partial^2 u}{\partial x^2} \)</li>
            <li><strong>Analytical Solution:</strong>
              \[
              u(x,t) = \frac{1}{\sqrt{4\pi \alpha t}} \exp\left(-\frac{(x - vt - 0.5)^2}{4\alpha t}\right)
              \]
            </li>
            <li><strong>Numerical Solver:</strong> Implicit finite difference
              scheme handling both advection and diffusion; inlet conditions
              are defined by the analytical solution.</li>
            <li><strong>Neural Network:</strong> Learns to predict
              \((\alpha, v) \in (0,1)^2\) from noisy snapshots of \(u(x,t)\).</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), ensuring physics-consistent parameter recovery.</li>
          </ul>
          <img src="PNN_AdvDif.png" alt="Advection-Diffusion training convergence plot" class="visual-content" />
        </div>
      </section>

      <!-- Case 3 -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 3 — Inverse modeling a 1D advection–diffusion–reaction system with fixed parameters</h3>
          <p><a href="https://github.com/ZhenwenWan/Hemodyn/blob/main/DSML/NNP_AdvDifRea.py">Code implementation 3</a></p>
          <ul>
            <li><strong>Advection–Diffusion–Reaction Equation:</strong> \( \frac{\partial u}{\partial t} + v \frac{\partial u}{\partial x} = \alpha \frac{\partial^2 u}{\partial x^2} + R(u) \), where \( R(u) \) models spatially heterogeneous reaction terms.</li>
            <li><strong>Synthesized Data Samples:</strong> Noisy measurements of \( u(x,t) \) are generated by simulating the forward PDE solver with known parameters \((\alpha, v, r_0, r_1)\) at random time points. Gaussian noise is added to simulate observation uncertainty.</li>
            <li><strong>Numerical Solver:</strong> Implicit finite difference scheme that handles all three processes—advection, diffusion, and spatially varying reactions—implemented as a differentiable module for backpropagation.</li>
            <li><strong>Neural Network:</strong> Maps input pairs of noisy solution fields and time into predicted parameters \((\alpha, v, r_0, r_1)\), using a two-layer MLP with bounded sigmoid output scaled to physical ranges.</li>
            <li><strong>Loss:</strong> \(\mathcal{L} = \| u_{\text{pred}} - u_{\text{true}} \|^2\), comparing simulated outputs under predicted parameters to noisy observations, enabling inverse inference.</li>
          </ul>
          <img src="PNN_AdvDifRea.png" alt="Advection-Diffusion-Reaction training convergence plot" class="visual-content" />
        </div>
      </section>
  <section>
    <h2>Case 4 — Inverse modeling a 1D hemodynamic system</h2>
    <p>The governing equations are based on conservation of mass and momentum, expressed in terms of flow rate <var>Q(x,t)</var> and cross‑sectional area <var>A(x,t)</var>:</p>
    <li><strong>Conservation of Mass:</strong></li>
    <p>$$\frac{\partial A}{\partial t} + \frac{\partial Q}{\partial x} = 0$$</p>
    <li><strong>Conservation of Momentum:</strong></li>
<p>
$$
\frac{\partial Q}{\partial t}
+ \frac{\partial}{\partial x}\left(\alpha \frac{Q^2}{A}\right)
+ \frac{A}{\rho}\,\frac{\partial P}{\partial x}
=
-\,K_R \frac{Q}{A}
+ \nu\,\frac{\partial^2 Q}{\partial x^2}
$$
</p>
<p>
The pressure \(P\) is still given by:
</p>
<p>
$$
P = P_0 + \beta\left(\sqrt{A} - \sqrt{A_0}\right)
$$
</p>
    <p>To numerically solve these PDEs, boundary conditions are required:</p>
    <li><strong>Inlet Boundary Conditions</strong></li>
    <ul>
      <li>Prescribe both <var>Q(t)</var> and <var>P(t)</var> (or equivalently <var>A(t)</var>) at the inlet to uniquely define inflow and pressure dynamics.</li>
    </ul>
    <li><strong>Outlet Boundary Conditions</strong></li>
    <p>Only <var>P(t)</var> is prescribed; <var>Q(t)</var> is inferred using one of four common models:</p>
    <ol>
      <li><strong>Dirichlet (Prescribed Pressure)</strong>: directly specify <var>P(t)</var>.</li>
      <li><strong>Resistance</strong>: <var>P(t) = R Q(t)</var>.</li>
      <li><strong>RCR (Windkessel)</strong>: three-element model relating <var>P</var> and <var>Q</var> via resistance and compliance.</li>
      <li><strong>Impedance/Structured Tree</strong>: uses impedance or structured tree model—<var>Q(t)</var> is computed via convolution with the inverse FT of admittance.</li>
    </ol>
    <p>In all cases, the user prescribes <var>P(t)</var> (or its defining parameters), and the solver infers <var>Q(t)</var> based on the chosen outlet model.</p>
    <h4>Numerical Algorithm</h4>
    <p><strong>Unknown fields:</strong> \(P_{i,j}, Q_{i,j}, A_{i,j}\) over \(i=0,\dots,N_x-1\); \(j=0,\dots,N_t-1\). Total unknowns: <em>3·N<sub>x</sub>·N<sub>t</sub></em>.</p>

    <p><strong>Constraints:</strong></p>
    <ul>
      <li><strong>Initialization</strong> (\(j=0\)): \(P_{i,0}, Q_{i,0}, A_{i,0}\) are prescribed.</li>
      <li><strong>Periodicity</strong> (\(j=N_t-1\)): \(P_{i,N_t-1}=P_{i,0}\), \(Q_{i,N_t-1}=Q_{i,0}\), \(A_{i,N_t-1}=A_{i,0}\).</li>
      <li><strong>Boundary Conditions</strong>:
        <ul>
          <li>Inlet (\(i=0\)): both \(Q_{0,j}\) and \(P_{0,j}\) provided.</li>
          <li>Outlet (\(i=N_x-1\)): \(P_{N_x-1,j}\) prescribed; \(Q_{N_x-1,j}\) inferred using SimVascular models (Resistance, RCR/Windkessel, Impedance/Structured-tree).</li>
        </ul>
      </li>
      <li><strong>PDE equations</strong> (interior nodes \(0<i<N_x-1\), \(0<j<N_t-1\)) using central finite differences:
        <p>Mass: \(\frac{A_{j+1,i}-A_{j,i}}{\Delta t} + \frac{Q_{j,i+1}-Q_{j,i-1}}{2\Delta x} = 0\)</p>
        <p>Momentum: \(\frac{Q_{j+1,i}-Q_{j,i}}{\Delta t} + \frac{\partial}{\partial x}(\alpha \frac{Q^2}{A}) + \frac{A}{\rho}\frac{\partial P}{\partial x} + K_R \frac{Q}{A} = 0\)</p>
        <p>Constitutive: \(P_{j,i} - [P_0 + \beta (\sqrt{A_{j,i}} - \sqrt{A_0})] = 0\)</p>
      </li>
    </ul>

    <p>Altogether, these give \(3(N_t-2)(N_x-2)\) equations matching the interior unknowns.</p>

    <h4>Solver outline:</h4>
    <ol>
      <li>Assemble residual vector \(\mathbf{R}(U)\) across all unknowns \(U = \mathrm{vec}(P,Q,A)\).</li>
      <li>Solve nonlinear system \(\mathbf{R}(U)=0\) using Newton–Krylov:
        <ul>
          <li>Approximate Jacobian–vector product via finite differences.</li>
          <li>Solve correction \(\Delta U\) using GMRES + ILU preconditioner (avoiding direct factorization errors).</li>
        </ul>
      </li>
      <li>Iterate until convergence \(\|\mathbf{R}\| < tol\).</li>
    </ol>

    <p>This fully couples the 1D system in space and time, enforcing periodic behavior and solving for the complete space-time field in a single unified step.</p>
  </section>
    
      <!-- =============================== -->
      <!-- Case 5 — Newly Added Section -->
      <!-- =============================== -->
      <section class="content-block">
        <div class="text-content">
          <h3>Case 5 — Dual Pipeline Framework for Wearable Physiological Modeling</h3>

          <h4>Executive Summary</h4>
          <p>
            I propose a bi-directional modeling architecture that combines
            (1) a forward, physiology-constrained generative pipeline, and
            (2) an inverse inference pipeline, enabling robust detection and
            interpretation of stress, cognitive load, and sleep disruptions
            from noisy wearable biosignals. This hybrid approach goes beyond
            black-box prediction by integrating mechanistic understanding with
            machine learning to improve interpretability, generalization, and
            event discovery over a long-term (&gt;6 months) engagement.
          </p>

          <h4>Pipeline A – Forward (Mechanistic Generative Model)</h4>
          <p><strong>Purpose:</strong> Generate realistic wearable biosignals
            (e.g., heart rate, HRV, accelerometry) from latent physiological and
            contextual states.</p>

          <h5>Structure</h5>
          <ul>
            <li><strong>Input Layer – Exogenous Drivers</strong><br>
              Sleep/wake timing, activity context, stressor indicators, circadian phase.
            </li>
            <li><strong>Hidden Layer – Latent Physiological Dynamics</strong><br>
              Autonomic balance, fatigue/recovery state, respiratory modulation.
            </li>
            <li><strong>Interpretable Output Parameters</strong><br>
              Heart rate set-points, responsiveness gains, baroreflex sensitivity proxies.
            </li>
            <li><strong>Physics Measurement Layer</strong><br>
              Differentiable physiological signal model translating latent state to HR/HRV and accelerometry streams under realistic noise and artifact models.
            </li>
          </ul>

          <h5>Deliverables</h5>
          <ul>
            <li>A differentiable generative simulator capable of producing wearable biosignals consistent with underlying states.</li>
            <li>Synthetic data generation.</li>
            <li>Personalized calibration.</li>
            <li>Counterfactual exploration (what-if stress/cognitive load scenarios).</li>
          </ul>

          <p>
            This pipeline leverages mechanistic models and neural ODE–style physics layers (PINNs)
            to construct physiologically grounded generative modules.
          </p>

          <h4>Pipeline B – Inference (Measurement-to-Event, Reverse Information Flow)</h4>

          <p>
            <strong>Main feature:</strong> Pipeline B takes the <em>outputs of Pipeline A’s Physics Measurement Layer</em>
            (wearable signals such as HR / RR, HRV features, accelerometry, etc.) as inputs and infers upstream
            <em>status/events</em> (stress, cognitive load, sleep disruptions). “Reverse” here refers to reversing the
            <em>information flow</em> (signals &rarr; events), not reconstructing Pipeline A’s internal physiological mechanisms.
          </p>

          <p><strong>Purpose:</strong> Provide a robust, deployable detection and interpretation pipeline for noisy, real-world
            wearable data, without introducing additional mechanistic layers in the inverse path.</p>

          <h5>Core Components</h5>
          <ul>
            <li><strong>Signal preprocessing &amp; quality control</strong><br>
              Artifact rejection (motion/PPG issues, ectopy if RR is available), missingness handling, and a
              <em>signal-quality/confidence</em> score used to down-weight unreliable segments.</li>

            <li><strong>Contextual regime segmentation (lightweight internal representation)</strong><br>
              Rest vs movement vs sleep-like regimes inferred primarily from accelerometry and circadian timing.
              This is a practical gating variable, not a physiological hidden-state model.</li>

            <li><strong>Multi-resolution feature extraction</strong><br>
              Short windows (10–30 s) for rapid changes, medium windows (2–5 min) for HRV stability metrics, and
              long windows (30–90 min) for sustained episodes and emerging patterns.</li>

            <li><strong>Event inference (supervised + unsupervised)</strong><br>
              Supervised detection when labels exist; weakly supervised / unsupervised discovery (change-point detection,
              clustering/representation learning) to identify emerging or previously unlabeled events.</li>

            <li><strong>Uncertainty-aware outputs</strong><br>
              Calibrated probabilities and confidence intervals (or equivalent) plus explicit “unknown/low confidence”
              flags when signals are ambiguous or heavily confounded.</li>
          </ul>

          <p>
            Pipeline B is intentionally simplified relative to Pipeline A: it focuses on reliable event inference in the
            measurement space. Pipeline A can still support Pipeline B via synthetic augmentation, personalization priors,
            and signal-level consistency checks (i.e., detected events should be explainable in terms of the observable signals,
            without requiring recovery of detailed physiological states).
          </p>

          <h4>Closed-Loop Integration (Key Enhancement)</h4>
          <p>
            Rather than treating the pipelines independently, the framework operates in a closed-loop cycle:
          </p>
          <ol>
            <li>Inverse pipeline retrieves latent trajectories and parameters.</li>
            <li>Forward pipeline reconstructs synthetic signals.</li>
            <li>Reconstruction errors drive calibration and model refinement.</li>
          </ol>

          <p>This enables:</p>
          <ul>
            <li>Model validation and self-consistency checks.</li>
            <li>Identification of emerging or novel latent events.</li>
            <li>Personalization across subjects and contexts.</li>
          </ul>

          <p>
            This feedback mechanism is critical in noisy real-world settings where labels are sparse and confounds are prevalent.
          </p>

          <h4>Phased 6-Month Plan</h4>
          <table border="1" cellpadding="8" cellspacing="0" style="border-collapse: collapse;">
            <tr>
              <th>Phase</th>
              <th>Objectives</th>
              <th>Deliverables</th>
            </tr>
            <tr>
              <td>1–2 months</td>
              <td>Robust preprocessing &amp; baseline modeling</td>
              <td>Workflow + baseline classification</td>
            </tr>
            <tr>
              <td>3–4 months</td>
              <td>Reverse Pipeline A (physics-&gt;params-&gt;states) with uncertainty</td>
              <td>Differentiable inverse estimator + personalized state trajectories</td>
            </tr>
            <tr>
              <td>5–6 months</td>
              <td>Closed-loop integration (inverse + forward) + event attribution/discovery</td>
              <td>Simulator + consistency validation &amp; personalization + emerging event discovery</td>
            </tr>
          </table>

          <p>
            Progress will be evaluated using systematic validation on real wearable datasets,
            with clear metrics such as ROC, F1-score, calibration quality, and reconstruction error.
          </p>
        </div>
      </section>

</main>

    <footer class="project-footer">
      <p>&copy; 2025 Zhenwen Wan. All rights reserved.</p>
    </footer>
  </div>
</body>

</html>

